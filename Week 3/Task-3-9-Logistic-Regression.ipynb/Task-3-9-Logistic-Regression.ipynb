{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we are going to implement logistic regression to solve a binary classification problem. In particular, you will have to:\n",
    "\n",
    "* Complete `logRegParamEstimates(XTrain,yTrain)` function that fits a logistic regressor to data using the Gradient Descent algorithm.\n",
    "* Complete a function `logRegNEWRegrPredict(XTrain, yTrain, xTest)` to implement logistic regression algorithm and run it on the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The required libraries for this notebook are pandas, sklearn, scipy, numpy and matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "# from pandas.tools.plotting import scatter_matrix\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "import matplotlib.patches as patches\n",
    "from scipy.special import expit\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data\n",
    "We will use the dataset ***classification data.txt***. It characterizes 2 different classes of fruits (apple or non apple) based on 7 features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the TXT file\n",
    "fruits = pd.read_table('./classification_data.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "feature_names = ['mass', 'width', 'height', 'color_score']\n",
    "x = fruits[feature_names]\n",
    "y = fruits['fruit_label']\n",
    "\n",
    "# Split the data into training and testing(75% training and 25% testing data)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y,random_state=0)\n",
    "\n",
    "# Pre-process data\n",
    "scaler = MinMaxScaler() # This estimator scales and translates each feature individually such that it is in the given range on the training set, default between(0,1)\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Use logistic regression from a library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first see how logistic regression can be implemented using already available functions from the scikit-learn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.60      0.67         5\n",
      "           3       0.67      0.80      0.73         5\n",
      "\n",
      "    accuracy                           0.70        10\n",
      "   macro avg       0.71      0.70      0.70        10\n",
      "weighted avg       0.71      0.70      0.70        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sklearn functions implementation\n",
    "def logRegrPredict(x_train, y_train,xtest ):\n",
    "    # Build Logistic Regression Model\n",
    "    logreg = LogisticRegression(solver='lbfgs')\n",
    "    # Train the model using the training sets\n",
    "    logreg.fit(x_train, y_train)\n",
    "    y_pred= logreg.predict(xtest)\n",
    "    #print('Accuracy on test set: {:.2f}'.format(logreg.score(x_test, y_test)))\n",
    "    return y_pred\n",
    "\n",
    "y_pred = logRegrPredict(x_train, y_train,x_test)\n",
    "print('Accuracy on test set: '+str(accuracy_score(y_test,y_pred)))\n",
    "print(classification_report(y_test,y_pred))#text report showing the main classification metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Implement your own logistic regression function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "You will be given the partially-implemented`paramEstimates(xTrain, yTrain)` function that returns the parameters estimated by gradient descent. You are asked to complete the cost function as follows:\n",
    "\n",
    "\\begin{align}\n",
    "J\\left(\\theta \\right) & =  -{\\frac{1}{n}}[\\sum_{i=1}^n \\left(y_i \\log_2(P_r(\\hat{y}=1|x_i;\\theta))+(1-y_i)\\log_2(1-P_r(\\hat{y}=1|x_i;\\theta)) \\right)]\\\\\n",
    "\\end{align}\n",
    "\n",
    "You are also asked to complete the `logRegrNEWRegrPredict(xTrain, yTrain, xTest)` function, or write your own, that returns the output variable y given the input features x as follows: \n",
    "\\begin{align}\n",
    "\\hat{y} & = \\frac{1}{1+e^{-\\theta^{*t}x}}\n",
    "\\end{align}\n",
    "\n",
    "***Remember that we train on `xTrain` and `yTrain`!***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1. / (1. + np.exp(-z))\n",
    "\n",
    "def loss(h, y):\n",
    "    return (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean()\n",
    " \n",
    "def logRegParamEstimates(xTrain, yTrain):\n",
    "    intercept = np.ones((xTrain.shape[0], 1))\n",
    "    xTrain = np.concatenate((intercept, xTrain), axis=1)\n",
    "    yTrain[yTrain > 1] = 0\n",
    "    theta = np.zeros(xTrain.shape[1])\n",
    "    for i in range(100):\n",
    "        z = np.dot(xTrain, theta)\n",
    "        h = sigmoid(z)\n",
    "        lr = 0.01\n",
    "        gradient = loss(h, yTrain)\n",
    "        theta = theta - lr*gradient\n",
    "    return theta\n",
    "\n",
    "def logRegrNEWRegrPredict(xTrain, yTrain,xTest ):\n",
    "    theta = logRegParamEstimates(xTrain, yTrain)\n",
    "    intercept = np.ones((xTest.shape[0], 1))\n",
    "    xTest = np.concatenate((intercept, xTest), axis=1)\n",
    "    sig = sigmoid(np.dot(xTest, theta))\n",
    "    y_pred1 = []\n",
    "    for x in sig:\n",
    "        print(x)\n",
    "        if x > 0.5:\n",
    "            y_pred1.append(3)\n",
    "        else:\n",
    "            y_pred1.append(1)\n",
    "    \n",
    "    return y_pred1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07941491499064234\n",
      "0.14401630327980314\n",
      "0.13658670929196423\n",
      "0.12360927828779202\n",
      "0.1718929088110426\n",
      "0.031557077824981385\n",
      "0.09187892023408127\n",
      "0.17961732165833164\n",
      "0.15524415948979306\n",
      "0.20591419027398608\n",
      "Accuracy on test set: 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      1.00      0.67         5\n",
      "           3       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.50        10\n",
      "   macro avg       0.25      0.50      0.33        10\n",
      "weighted avg       0.25      0.50      0.33        10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tkate\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred1 = logRegrNEWRegrPredict(x_train, y_train,x_test)\n",
    "print('Accuracy on test set: '+str(accuracy_score(y_test,y_pred1)))\n",
    "print(classification_report(y_test,y_pred1))#text report showing the main classification metrics\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred1)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "interpreter": {
   "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
