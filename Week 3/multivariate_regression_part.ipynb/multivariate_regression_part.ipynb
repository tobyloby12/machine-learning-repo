{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Multivariate Regression(GD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we are going to implement multivariate regression(gradient descent version). In particular, you will have to:\n",
    "\n",
    "* Complete the function `cost_function` to implement cost function for multivariate regression(gradient descent version) algorithm.\n",
    "* Complete the function `GDmultiLinparamEstimates` to implement multivariate regression(gradient descent version) algorithm.\n",
    "\n",
    "Note we do not cover single value linear regression (gradient descent version) in this experiment as it is a similar one. You can play with it yourselves after going through this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The required libraries for this notebook are pandas, sklearn and numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data\n",
    "The data we are using is from ***multi_regr_data.csv***. It consists of 1000 data related to student marks. Each data point has 3 columns(marks) and we are going to use all of them for multivariate linear regression. In particular, we will use the first 2 marks to predict the 3rd mark.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 3)\n"
     ]
    }
   ],
   "source": [
    "# Loading the CSV file\n",
    "dataset=pandas.read_csv('./datasets/multi_regr_data.csv')\n",
    "print(dataset.shape) #(data_number,feature_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data, we will use first 2 columns as features and the 3rd columns as target.\n",
    "X = dataset[list(dataset.columns)[:-1]]\n",
    "Y = dataset[list(dataset.columns)[-1]] \n",
    "\n",
    "# As pointed out in previous lab, we need to add a constant feature\n",
    "intercept=np.ones((X.shape[0],1))\n",
    "X=np.concatenate((intercept,X),axis=1)\n",
    "\n",
    "# Split the data into training and testing(75% training and 25% testing data)\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(X, Y, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize using Gradient Descent Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cost function is defined as follows:\n",
    "\\begin{align}\n",
    "J\\left(\\beta \\right) & =  {\\frac{1}{2n}}\\sum_{i=1}^n \\left(y_i - \\hat{y_i} \\right)^2\\\\\n",
    "\\end{align}\n",
    "or \n",
    "\\begin{align}\n",
    "J\\left(\\beta \\right) & =  {\\frac{1}{2n}}SSR\\left(y_i,\\hat{y_i} \\right)\\end{align}\n",
    "\n",
    "You are asked to implement this cost function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2470.11\n"
     ]
    }
   ],
   "source": [
    "def cost_function(X, Y, beta):\n",
    "    #  complete the code below.\n",
    "    cost = np.square(Y - np.matmul(X, beta)).mean()/2\n",
    "    \n",
    "    return cost\n",
    "\n",
    "# initialize B\n",
    "beta= np.zeros(3, dtype=float)\n",
    "\n",
    "# cal initial cost\n",
    "inital_cost = cost_function(X, Y, beta)\n",
    "print(inital_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradient Descent Steps:**\n",
    "1. Initialize values: \\begin{align}\\beta_0,\\beta_1,…,\\beta_n\\end{align}  It is suggested you initilize with 0.\n",
    "2. Iteratively update, until convergence: \\begin{align} β_j : =  β_j - \\alpha {\\frac{\\partial}{\\partial J\\left(\\beta_j \\right) }}J\\left(\\beta \\right) \\\\ \\end{align}  α: learning rate.\n",
    "\n",
    "**Hint:** Step 2 function can also be written as \\begin{align} β_j : =  β_j - \\alpha \\frac{1}{n}\\sum_{i=1}^n \\left(\\hat{y_i} - y_i \\right)x_{ij}\\\\ \\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.47889172  0.09137252  0.90144884]\n",
      "10.475123473539167\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def GDmultiLinparamEstimates(X, Y, beta, learning_rate, iterations):\n",
    "    cost_history = [0] * iterations\n",
    "    n = X.shape[0]\n",
    "    beta = np.zeros(X.shape[1], dtype=float)\n",
    "    \n",
    "    for iteration in range(iterations):\n",
    "        #  complete the code below.   \n",
    "        \n",
    "        # Gradient Calculation\n",
    "        gradient = np.dot((np.matmul(X, beta) - Y), X)/n\n",
    "        # Changing Values of beta using Gradient\n",
    "        beta = beta - learning_rate*gradient\n",
    "        \n",
    "        cost = cost_function(X, Y, beta)\n",
    "        cost_history[iteration] = cost\n",
    "        \n",
    "    return beta, cost_history\n",
    "\n",
    "iterations = 100000 # a value of iteration\n",
    "learning_rate = 0.0001 # alpha\n",
    "\n",
    "\n",
    "\n",
    "# run your algorithm\n",
    "newB, cost_history = GDmultiLinparamEstimates(X, Y, beta, learning_rate, iterations)\n",
    "\n",
    "# New Values of B\n",
    "print(newB)\n",
    "# Final Cost of new B\n",
    "print(cost_history[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final hypothesis for the whole dataset (i.e. X and Y as defined above) should be:\n",
    "\\begin{align}\n",
    "y & = -0.47889172 + 0.09137252*x_1 + 0.90144884*x_2\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congrat! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you have learned how to implement multivariate regression algorithm using gradient descent method. The next step would be to test your algorithm on test dataset, which we encourage you to do it yourself given the experience in previous lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "newB, cost_history = GDmultiLinparamEstimates(xtrain, ytrain, beta, learning_rate, iterations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = np.dot(xtest,newB)\n",
    "print(y_pred)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "interpreter": {
   "hash": "4e2b8f6a23295008f793d8e1337b3ae082602f5831d250bb4d59fc8c17b79005"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('MLenv': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
